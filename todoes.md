
### 1. Суть задачи: Агрегатор знаний (Enrichment Aggregator)

Мы превращаем метод `Suggest` из простого "поиска по базе" в **интеллектуального агента**, который:
1.  Принимает слово от пользователя.
2.  Опрашивает **все доступные провайдеры** (сейчас Free Dictionary API, в будущем — LLM, Google Translate, Oxford и т.д.).
3.  Кэширует "сырые" ответы от каждого провайдера в `dictionary_*` таблицах (чтобы не платить за API и не ждать в следующий раз).
4.  Возвращает фронтенду **сводный отчет**: "Вот что я нашел по слову X: 3 варианта транскрипции (источник А, Б), 5 вариантов перевода (источник В), 2 определения".

### 2. Изменения в архитектуре данных (Backend)

Чтобы хранить данные из разных источников, нам нужно немного уточнить логику таблицы `dictionary_words`.

Сейчас там `text` уникален (`UNIQUE`). Но если мы хотим хранить версию слова от "FreeDict" и версию от "GPT-4", нам нужно либо:
1.  **Сливать всё в одну запись** (сложно обновлять, каша в данных).
2.  **Хранить разные записи для разных источников** (чище).

**Решение:** Уникальным ключом в `dictionary_words` должна быть пара **`(text, source)`**.
То есть в БД могут лежать две записи для слова "run": одна из `free_dictionary`, другая из `openai`.

### 3. План реализации

Разделим работу на 4 этапа.

#### Этап 1: Слой внешних интеграций (Providers)
Нужно создать интерфейс для внешних словарей, чтобы их можно было легко добавлять (плагин-система).

*   **Интерфейс:** `DictionaryProvider { Fetch(word) -> Result }`.
*   **Реализация 1:** `FreeDictionaryProvider` (ходит в API, парсит JSON).
*   **Менеджер:** `ProviderManager`, который хранит список провайдеров и умеет опрашивать их параллельно (через горутины).

#### Этап 2: Слой хранения (Caching)
Обновляем логику репозитория `dictionary`.

*   **Миграция:** Изменить `UNIQUE(text)` на `UNIQUE(text, source)` в таблице `dictionary_words`.
*   **Логика сохранения:** Метод `Save(WordData)` должен сохранять слово с указанием конкретного источника.
*   **Логика чтения:** Метод `GetByText(text)` теперь должен возвращать не одно слово, а `[]DictionaryWord` (список вариантов из разных источников).

#### Этап 3: GraphQL API (Presentation)
Нужно изменить структуру ответа, чтобы фронтенд понимал, откуда пришла инфа.

Вместо плоских полей делаем объекты с метаданными:

```graphql
type WordSuggestion {
  text: String!
  # Массив вариантов транскрипции
  transcriptions: [SuggestionOption!]! 
  # Массив переводов
  translations: [SuggestionOption!]!
  # Массив определений
  definitions: [SuggestionOption!]!
  # Массив примеров
  examples: [SuggestionOption!]!
}

type SuggestionOption {
  value: String!      # Сама транскрипция или перевод
  source: String!     # "FreeDict", "Wiktionary"
  meta: String        # Доп. инфо (например "US", "UK" для аудио, или "Verb" для перевода)
}
```

#### Этап 4: Фронтенд (Selection UI)
Обновляем `AddWordDialog`.

*   Вместо автоматической подстановки первого значения делаем **Dropdown** или **Popover**.
*   Когда пользователь нажимает "волшебную палочку" у поля "Транскрипция", выпадает список:
    *   `/rʌn/` (US, FreeDict)
    *   `/ran/` (UK, FreeDict)
*   Пользователь кликает — значение подставляется.

---

### 4. Желаемый результат (User Flow)

1.  Ты открываешь диалог добавления слова.
2.  Вводишь "world".
3.  Нажимаешь **Global Autofill ("Заполнить всё")**.
    *   Система опрашивает API.
    *   Если вариант всего один (или есть явный лидер) — подставляет его.
    *   Если вариантов много — подставляет самый популярный, но добавляет индикатор "Есть другие варианты".
4.  Или ты нажимаешь **"Палочку"** конкретно у поля "Definition".
    *   Появляется список:
        *   *"The earth, together with all of its countries..."* (FreeDict)
        *   *"A planet like the Earth"* (Wiktionary)
    *   Ты выбираешь то, которое тебе больше нравится.
